---
title: "Roshambot"
date: "2016"
lede: "An artificially intelligent disembodied hand that plays rock-paper-scissors."
link: ""
repo: "https://github.com/MoonshotLab/RoShamBot"
order: 3
publish: true
lang: "Python, Arduino"
---

import ZoomImage from 'components/ZoomImage';
import XA from 'components/ExternalAnchor';

import hand from './hand.jpg';
import handZoom from './hand-zoom.jpg';
import pedestal from './pedestal.jpg';
import pedestalZoom from './pedestal-zoom.jpg';

Roshambot (more annoyingly styled RoShamBot) was my first project working with <XA href="https://www.barkleyus.com/">Barkley</XA>'s innovation lab, <XA href="http://moonshot.barkleyus.com">Moonshot</XA>. The idea for the project was to make artificial intelligence more easily understandable. We wanted to make the experience accessible to anyone, regardless of technical experience, so we decided to try and train an artificial intelligence to play a common, universal game. As luck would have it, a local bank just a few blocks away from Barkley holds an annual Rock-Paper-Scissors competition, et voil√†, we decided to create an artificially intelligent RPS player.

<div class="blog-inset">
  <ZoomImage src={hand} zoomSrc={handZoom} alt='Roshambot Hand' />
</div>

The bot is comprised of an animatronic, 3D-printed hand rising out of a pedestal which houses both the laptop running the main logic program, a <XA href="https://en.wikipedia.org/wiki/Leap_Motion#Technology">Leap Motion</XA> controller, as well as an Arduino Uno which communicates with the laptop and controls the lights and scoreboard. To play, a user walks up to the machine and holds their hand above the sensor for 5 seconds. Then, after a countdown, both the player and the bot play their hands, and the bot uses the Leap Motion controller to figure out what the human played, and if the throw was a win, loss, or tie.

<div class="blog-inset">
  <ZoomImage src={pedestal} zoomSrc={pedestalZoom} alt='Roshambot Hand' />
</div>

Roshambot maintains a database of every throw played against it, as well as the 'context' for each of those throws. This allows the bot to make inferences into how the individual plays, as well as how people tend to play, in general. It might find that people who play Rock and then Scissors typically switch back to Rock for the third throw. Or, a particular individual might tend towards Paper. In a game as random as Rock-Paper-Scissors, any universal commonalities are difficult to find, but with individual players, the bot can find and exploit subconscious biases, something I found to be truly remarkable (a fact shown by this eerily good <XA href="http://www.nytimes.com/interactive/science/rock-paper-scissors.html">simulation</XA> made by the New York Times).

<div class="blog-inset">
  <iframe class="youtube" src="https://www.youtube.com/embed/uS2KD28gLHM?rel=0&amp;showinfo=0" frameBorder="0" allowFullScreen></iframe>
</div>

While we weren't able to enter Roshambot into the RPS competition, we did bring it along to give competitors a chance to warm up. The crowd loved interacting with a device that was very clearly 'unhuman', yet possesses the capabilities to learn. Roshambot, at the end of the night, was bested by the winner of the RPS competition in a dramatic bout. But it was a close one, 2 to 3. The bot's been training, getting smarter and smarter, and we think it's only a matter of time before it returns to squash its puny human oppressors.

For more info, check out this <XA href="https://medium.com/moonshotlab/man-vs-machine-learning-40a39f7f936">post</XA> I wrote for the Moonshot <XA href="https://medium.com/moonshotlab">blog</XA>.
